<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
&lt;?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on Monax Industries</title>
    <link>http://localhost/tags/research/</link>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Mar 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost/tags/research/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Public Science: A Slightly More Practical Guide</title>
      <link>http://localhost/2016/03/15/chains-and-science-how-to/</link>
      <pubDate>Tue, 15 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid isPermaLink="true">http://localhost/2016/03/15/chains-and-science-how-to/</guid>
      <description>&lt;p&gt;This is Part 2 in a probably several part series. &lt;a href=&#34;https://db.erisindustries.com/science/2016/03/14/blockchains-and-science/&#34; target=&#34;_blank&#34;&gt;Here&amp;rsquo;s Part 1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The previous post was stricly a think-piece. Here, I outline some practical steps that a consortium of institutions could take to provide the basic building blocks needed to acheive a worldwide ledger of knowledge. The problem is this: how do we maximize the quantity of data (that has sufficient quality) in order to acheive scientific consensus on some topic of study? Most of what is proposed here is realistic today although several ideas will need significant refining before any practical implementation succeeds. A summary at the end distinguishes the possible from the now.&lt;/p&gt;

&lt;p&gt;The first step would be for a group of educational/research institutions to form a consortium. I don&amp;rsquo;t have a solution as to how this ought to play out; suffice to say the minimum requirement would be the desire to reduce reliance on publishers for publishing research. Each institution would be a validator on publicly accessible blockchain.&lt;/p&gt;

&lt;p&gt;With a chain in tow, step two would be for them all to run many &lt;a href=&#34;https://ipfs.io&#34; target=&#34;_blank&#34;&gt;IPFS&lt;/a&gt; nodes to ensure persistent availability of data (shameless plug: &lt;code&gt;eris services start ipfs&lt;/code&gt;). Crucially, we want the validator nodes and IPFS nodes running on the respective hardware of these institutions. Indeed, as public institutions, it ought to be their mandate to ensure access to knowledge for generations to come without reliance on cloud hosting providers.&lt;/p&gt;

&lt;p&gt;Next, for a specific field of research, some basic standards need to be agreed upon. These standards form the basis of what one might call smart contract factories. Roughly, three steps must be appropriately defined. Think of each as a smart contract which, once executed, allows the next steps to &amp;ldquo;be open&amp;rdquo; for execution.&lt;/p&gt;

&lt;p&gt;Ideally, for a nugget of scientific knowledge to be considered valid (i.e., &amp;ldquo;true&amp;rdquo;, as subjective as that may be), there should be consensus on the following standards:
a) pre-registering experiment,
b) acceptable data for said experiment and,
c) analysis of total (and ongoing! see Note, below) data set.&lt;/p&gt;

&lt;p&gt;Each step has some requirements. In no particular order:&lt;/p&gt;

&lt;p&gt;For b) we need specific standards for validating data from external sources (other labs, and, importantly, the public). That is, compatibility with crowd-sourced data/user-generated content should be the default. By having a) occur publicly, the opportunity for both: 1) feeback to refine the initial methodology and 2) anybody to propose experiments is available (which, with a proper content value sorting system would easily filter out pointless experiments). Finally, once the data are gathered, discussion and subsequent consensus on a scientific conclusion for the data set can be acheived, in a public forum (and &lt;em&gt;not&lt;/em&gt; behind closed-doors &lt;em&gt;and&lt;/em&gt; anonymous as the current status quo certainly is).&lt;/p&gt;

&lt;p&gt;Note: because there is a specific framework in place for accepting valid data for some pre-registered experiment, new data can be added to the set in perpetuity. Consequently, the conclusion derived from what is essentially a single experiment can evolve.&lt;/p&gt;

&lt;p&gt;What does this look like in practice? Well, in &lt;a href=&#34;https://db.erisindustries.com/science/2016/03/14/blockchains-and-science/&#34; target=&#34;_blank&#34;&gt;my previous post&lt;/a&gt; we have Alice and Bob. If Alice had announced, &lt;em&gt;ahead of time&lt;/em&gt; her intentions to attempt the groundbreaking experiment, then perhaps Bob could have contributed both: a) improvements to the methodology and, b) valid data by running the experiment himself. Both Alice and Bob would now each have a shared data set, thus increasing statistical power. In the previous post, neither Alice or Bob concluded anything groundbreak from their data. Perhaps the data set simply wasn&amp;rsquo;t large enough.&lt;/p&gt;

&lt;p&gt;This helps tackle the &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4550299/&#34; target=&#34;_blank&#34;&gt;increasingly problematic lack of reproducibility in psychological science&lt;/a&gt; and maybe, just maybe, the conclusion that &lt;a href=&#34;http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124&#34; target=&#34;_blank&#34;&gt;most research findings are false&lt;/a&gt; can be un-concluded.&lt;/p&gt;

&lt;p&gt;After Alice proposes the experiment and Bob suggests improvements, perhaps Charlie sees that it&amp;rsquo;s a great idea and happens to have a research laboratory five times the size; ideal for running such experiments at scale. Even better, let&amp;rsquo;s say the experiment is simple enough to run in the average &lt;a href=&#34;https://en.wikipedia.org/wiki/Do-it-yourself_biology&#34; target=&#34;_blank&#34;&gt;DIYbio&lt;/a&gt; lab and a data set orders of magnitude that was ever thought possible can be achieved.&lt;/p&gt;

&lt;p&gt;The data is collected and, eventually, analysed. Since the data is added in real-time and all the details of the ongoing experiment are available publicly, &lt;em&gt;anyone&lt;/em&gt; can run a statistical analysis and propose an interpretation. Again, creative content filtering schemes will be needed to ensure that the cream rises to the top.&lt;/p&gt;

&lt;p&gt;How is this different from the average research collaboration today in academia? Usually, collaborations are &lt;em&gt;ad-hoc&lt;/em&gt;, i.e., planned and all the roles divided up ahead of time. My proposal has collaboration happenening &lt;em&gt;post-hoc&lt;/em&gt; (once an experiment is proposed for pre-registration) and completely fluid, provided participants are generating useful content (data, if you will).&lt;/p&gt;

&lt;p&gt;The biggest challenge, as I&amp;rsquo;ve repeatedly alluded to, is having creative and well-implement reputation and reward schemes. Reasearchers need to somehow be compensated for their time and receive credit where credit is due. If this basic requirement can be satisfied then I&amp;rsquo;m hopeful we&amp;rsquo;ll see science accelerate its effeciency.&lt;/p&gt;

&lt;p&gt;To summarize, we need:&lt;/p&gt;

&lt;p&gt;1) a consortium of institutions,
2) running many IPFS nodes and,
3) acting as validators on a chain,
4) their researchers to publish planned experiments ahead of time (pre-registration),
5) data standards such that adding to the set is seamless and verifiable,
6) creative way of acheiving consensus on conclusions from analysis of data set,
6) a sane on-chain indexing method,
7) a meaningful user interface to pull it all together and, finally,
8) useful solutions to reputation/compensation problems.&lt;/p&gt;

&lt;p&gt;1-4 is, at a minimum, do-able today, as is a portion of (5), most of (6) and probably (7). As far as I can tell, enough pieces of the puzzle are in place to start implementing some of these basic features as soon as possible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Blockchains For Science: Aligning Research Incentives</title>
      <link>http://localhost/2016/03/14/blockchains-and-science/</link>
      <pubDate>Mon, 14 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid isPermaLink="true">http://localhost/2016/03/14/blockchains-and-science/</guid>
      <description>&lt;p&gt;Author&amp;rsquo;s Note: This post originally appeared as &lt;a href=&#34;https://bitcoinmagazine.com/articles/how-blockchains-can-further-public-science-1457972964&#34; target=&#34;_blank&#34;&gt;How Blockchains Can Further Public Science&lt;/a&gt; in Bitcoin Magazine. It is maintained here for archival purposes. Eventually, it&amp;rsquo;ll all be on IPFS. &lt;a href=&#34;https://db.erisindustries.com//science/2016/03/15/chains-and-science-how-to/&#34; target=&#34;_blank&#34;&gt;Part 2 is now available&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The thing that had me most excited about Bitcoin back in 2013 was its potential to re-align the incentives in academia and re-define how science and research is conducted.&lt;/p&gt;

&lt;p&gt;At the time, I was spending my days training rats in &lt;a href=&#34;https://en.wikipedia.org/wiki/Operant_conditioning_chamber&#34; target=&#34;_blank&#34;&gt;Skinner boxes&lt;/a&gt; to hunt crickets, listening to every possible Bitcoin explainer I could get my hands on. It took a good two years, and now the problem set is much clearer. This post a think-piece on how academia might be improved with blockchain technology.&lt;/p&gt;

&lt;p&gt;In what follows, I&amp;rsquo;ll discuss the problems that perturbed me the most and highlight potential solutions.&lt;/p&gt;

&lt;p&gt;Taught in every Research Methods 101 course, the file-drawer problem â€“ more generally referred to as &lt;a href=&#34;https://en.wikipedia.org/wiki/Publication_bias&#34; target=&#34;_blank&#34;&gt;publication bias&lt;/a&gt; â€“ does perhaps the most disservice to the scientific community at large. Allow me to explain.&lt;/p&gt;

&lt;p&gt;Alice is a researcher in cell biology. One night she dreams up an idea for a potentially groundbreaking experiment. Alice does the experiment, but does not get the result she expected. Alice tweaks a few parameters and tries again. Again, the result doesn&amp;rsquo;t fit her hypothesis. She eventually abandons this &amp;ldquo;groundbreaking&amp;rdquo; idea and moves on to other things.&lt;/p&gt;

&lt;p&gt;Bob is also a cell biology researcher. Independently of Alice â€“ but after reading much of the same literature â€“ Bob dreams up a similar &amp;ldquo;groundbreaking&amp;rdquo; experiment. After many tries, Bob also fails to get the expected result. Bob moves on.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s the problem here? Bob duplicated Alice&amp;rsquo;s efforts. Why? Alice&amp;rsquo;s efforts were not accessible to Bob; instead, they were siloed away under &amp;ldquo;things-that-don&amp;rsquo;t-work&amp;rdquo; on her hard drive.&lt;/p&gt;

&lt;p&gt;Both Alice and Bob have Internet. From a technical point of view, it should be really easy for Bob to access all the experiments Alice tried. But it isn&amp;rsquo;t easy. Why?&lt;/p&gt;

&lt;p&gt;Put simply: incentives. Publishing a &amp;ldquo;non-result&amp;rdquo; in a &amp;ldquo;third-tier&amp;rdquo; journal won&amp;rsquo;t advance Alice&amp;rsquo;s career the way a &amp;ldquo;significant&amp;rdquo; result in, say, &lt;a href=&#34;https://www.nature.com&#34; target=&#34;_blank&#34;&gt;Nature&lt;/a&gt; will. Writing up the article and going through the submission process probably won&amp;rsquo;t happen because &lt;a href=&#34;https://www.youtube.com/watch?v=8cT_Ulmcrys&#34; target=&#34;_blank&#34;&gt;nobody has time for that&lt;/a&gt;. Even though science advances mostly when we discover &lt;a href=&#34;https://en.wikipedia.org/wiki/Falsifiability&#34; target=&#34;_blank&#34;&gt;what doesn&amp;rsquo;t work&lt;/a&gt;; most of what doesn&amp;rsquo;t work, isn&amp;rsquo;t known. Instead, everything that doesn&amp;rsquo;t work is locked up in that researchers&amp;rsquo; file drawer.&lt;/p&gt;

&lt;p&gt;Alice could very well publish her results informally on her blog, or to a handful of journals (e.g. &lt;a href=&#34;http://journals.plos.org/plosone/s/journal-information/&#34; target=&#34;_blank&#34;&gt;Plos ONE&lt;/a&gt;) that don&amp;rsquo;t use statistical significance as a metric for publication (but still charge hefty publication fees). Although things are changing, this is far from the norm. And, as far as I could tell from 5 years in academia, the scale of duplicate work across labs around the world is both unknowable and likely enormous. It isn&amp;rsquo;t time consuming for these data to be published, but I suspect many academics don&amp;rsquo;t feel it is worth their time, or that the contribution isn&amp;rsquo;t meaningful enough if it isn&amp;rsquo;t in a prestigious journal, or that it won&amp;rsquo;t be archived and indexed properly. Who knows?&lt;/p&gt;

&lt;p&gt;What is known is that it&amp;rsquo;s definitely a problem.&lt;/p&gt;

&lt;p&gt;The concepts of &lt;a href=&#34;https://cos.io/prereg/?utm_source=Open+Science+Framework+General&amp;amp;utm_campaign=9bbf63c095-OFFICIAL_11th_OSF_Message1_5_2016&#34; target=&#34;_blank&#34;&gt;pre-registering experiments&lt;/a&gt; and &lt;a href=&#34;https://thewinnower.com/&#34; target=&#34;_blank&#34;&gt;widening the scope of acceptable citations&lt;/a&gt; begin to address this issue and will likely reap enormous benefits across academia. (I&amp;rsquo;ll have more to say on this in the future with respect to smart contract factories for experiments). However, the challenge â€“ assuming we want this knowledge free, distributed, and easily accessible (forever) to anyone with an Internet connection â€“ is archiving and indexing all the content such that our assumption is satisfied.&lt;/p&gt;

&lt;p&gt;The emergence of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Sci-Hub&#34; target=&#34;_blank&#34;&gt;Sci-Hub&lt;/a&gt; (see the &lt;a href=&#34;http://bigthink.com/neurobonkers/a-pirate-bay-for-science&#34; target=&#34;_blank&#34;&gt;Robin Hood of Science&lt;/a&gt; for the an excellent review) is promising in that it provides free access to vast stores of human knowledge; knowledge otherwise inaccessible if &lt;a href=&#34;http://www.iflscience.com/editors-blog/elsevier-acts-against-research-article-pirate-sites-and-claims-irreparable-harm&#34; target=&#34;_blank&#34;&gt;Elsevier had their way&lt;/a&gt;. But this solution is not distributed and, as far as I can tell, offers no permanent archival solution.&lt;/p&gt;

&lt;p&gt;Enter the InterPlanetary File System: &lt;a href=&#34;https://ipfs.io&#34; target=&#34;_blank&#34;&gt;IPFS&lt;/a&gt; has emerged as the most likely candidate for long-term knowledge preservation. Using (among other future-proofing features) content-based addressing (a hash) rather than location-based addressing (a URL), reliance on central servers is all but eliminated.&lt;/p&gt;

&lt;p&gt;And IPFS definitely plays nice with blockchains. Enter indexing. We need a registry to both track the hashes of all relevant content and update them. Ideally, such a registry would be shared across many educational institutions, which would be validators on a permissioned consortium blockchain. This strikes me as a likely direction for such institutions that are having to re-invent themselves in the digital age. Indeed, they should be the ones retaining the intellectual property of the researcher, not for-profit journals!&lt;/p&gt;

&lt;p&gt;This was the underlying motivation behind the &lt;a href=&#34;https://github.com/eris-ltd/toadserver&#34; target=&#34;_blank&#34;&gt;toadserver&lt;/a&gt;). It takes an uploaded file, gets its IPFS hash, registers the file name and hash in the &lt;a href=&#34;https://github.com/eris-ltd/eris-db&#34; target=&#34;_blank&#34;&gt;eris:db&lt;/a&gt; name registry and finally, adds the file to n IPFS nodes. It&amp;rsquo;s really just a glorified database, but with write permissions across stakeholders who might not fully trust each other. This is all well and good, though it&amp;rsquo;s not going to revolutionize science overnight.&lt;/p&gt;

&lt;p&gt;Another failing of academic research is its inability to effectively incorporate user-generated content. As a student of animal behavior, I watch in awe at the scientifically interesting (and relevant) discussion about &lt;a href=&#34;https://www.reddit.com/r/aww/comments/2jpal5/trick_your_cat_with_a_circle/&#34; target=&#34;_blank&#34;&gt;tricking your cat into a circle&lt;/a&gt; and wonder how to parse this content into useful data that might lead to a scientifically sound conclusion.&lt;/p&gt;

&lt;p&gt;As far as I can tell, the public has a thirst to &lt;a href=&#34;https://www.reddit.com/r/science/wiki/scienceamaseries&#34; target=&#34;_blank&#34;&gt;understand â€“ and participate in â€“ scientific inquiry&lt;/a&gt;; a thirst left wholly unquenched by mainstream academia. Publishers that charge 40 bucks per article aren&amp;rsquo;t helping either. A big challenge â€“ likely solved by creative incentive/reputation schemes â€“ is compensating researchers for their time. That discussion is probably too early to have.&lt;/p&gt;

&lt;p&gt;In the meantime, how can we aggregate useful user-generated content to improve the throughput of scientific research? The current focus of using a blockchain to streamline financial services is fine, but let&amp;rsquo;s talk about automating knowledge discovery.&lt;/p&gt;

&lt;p&gt;When first dreaming up chain-based apps, one idea in particular stuck with me. &lt;a href=&#34;https://en.wikipedia.org/wiki/Population_dynamics&#34; target=&#34;_blank&#34;&gt;Population dynamics&lt;/a&gt; â€“ the study of geographical distribution of life on earth i.e., analyzing &amp;ldquo;where life is&amp;rdquo; â€“ is both a logistical nightmare and labor intensive. Roughly: 1) get a research grant, 2) hire some graduate students, 3) gather data (field work), and 4) analyze &amp;amp; publish the data. The problem: 1) is time-consuming and ultra-competitive, 2) is fairly easy, 3) is time-consuming, as is 4) since it&amp;rsquo;s rarely outsourced and the raw data is usually siloed away anyway. Five years later, the research team has a conclusion about ant diversity in one small region of Africa. &lt;a href=&#34;https://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions&#34; target=&#34;_blank&#34;&gt;Science is incremental indeed&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Last week, Google &lt;a href=&#34;http://techcrunch.com/2016/02/18/google-opens-its-cloud-vision-api-to-all-developers/&#34; target=&#34;_blank&#34;&gt;released to the public&lt;/a&gt; its &lt;a href=&#34;https://cloud.google.com/vision/&#34; target=&#34;_blank&#34;&gt;Cloud Vision API&lt;/a&gt;, a nifty set of tools for analyzing images. For example, if you send it a picture of what is clearly a marmot, the API will return a response with the description &amp;ldquo;marmot&amp;rdquo; and a match score (i.e., degree of certainty that the image is, in fact, a marmot). What happens when you combine this functionality with a blockchain?&lt;/p&gt;

&lt;p&gt;All of a sudden, the submission of content (well, images) that meet specific parameters (quality is in the eye of the beholder) can be incentivized. That is, the content can be checked for its purported authenticity before being added to a shared database for subsequent analysis. For example, the &lt;a href=&#34;http://marmots.org/observer-program/&#34; target=&#34;_blank&#34;&gt;Marmot Recovery Foundation&amp;rsquo;s Observer Program&lt;/a&gt; could have a mobile app that allows users to submit geo-tagged images of marmots to be used for analysis in exchange for tokens â€“ tokens redeemable for marmot merchandise.&lt;/p&gt;

&lt;p&gt;Perhaps the budding school-aged scientist of the future will spend his days traipsing through the woods, taking pictures of ants, classifying them and adding everything to a chain run by a consortium of colleges and universities. The better the classifications he submits, the more tokens he earns â€“ tokens redeemable at any of the participating institutions as tuition, for example. Applications like the &lt;a href=&#34;http://lifescanner.net/&#34; target=&#34;_blank&#34;&gt;LifeScanner app&lt;/a&gt; and &lt;a href=&#34;http://m.plantnet-project.org/&#34; target=&#34;_blank&#34;&gt;PlantNet&lt;/a&gt; get us closer to such a goal.&lt;/p&gt;

&lt;p&gt;Enough talk. About a week ago, I put together the &lt;a href=&#34;https://github.com/eris-ltd/marmot&#34; target=&#34;_blank&#34;&gt;Marmot Checker&lt;/a&gt;, which is another piece of the puzzle in terms of automating knowledge generation throughput. Briefly, an image is uploaded, processed, and sent to the Google Cloud Vision API to get descriptions of the image; these descriptions are checked against a user-defined list of words, and if there is a match, the image is added to the toadserver. Although the implementation is quite is simple, a few hundred lines more of code and you&amp;rsquo;d have, say, a smart contract that sends the submitter of matched content some amount of tokens as a function of the match score and/or the users&amp;rsquo; reputation.&lt;/p&gt;

&lt;p&gt;On the whole, this is part a growing set of tools for the scientific community. Already we&amp;rsquo;re seeing more and more startups building tools to streamline the collaboration workflow process between research laboratories. â€¨â€¨That won&amp;rsquo;t cut it so long as the data is siloed within research labs/groups, journals are pay-per-view for the public and the average citizen hasn&amp;rsquo;t the means or method to contribute meaningfully to global shared knowledge. After all, shouldn&amp;rsquo;t &lt;a href=&#34;https://en.wikipedia.org/wiki/Citizen_science&#34; target=&#34;_blank&#34;&gt;citizen science&lt;/a&gt; really be called science proper? With blockchains I think it can be.&lt;/p&gt;

&lt;p&gt;The fight for open access to knowledge has been an ongoing battle â€“ a battle that ultimately took &lt;a href=&#34;http://bigthink.com/neurobonkers/the-robin-hood-of-science-the-missing-chapter&#34; target=&#34;_blank&#34;&gt;Aaron Swartz&amp;rsquo;s life&lt;/a&gt; while simultaneously stalling the progress of humanity and lining the pockets of shareholders. All this to protect copyright yet in clear violation of the &lt;a href=&#34;http://www.un.org/en/universal-declaration-human-rights/&#34; target=&#34;_blank&#34;&gt;Univerisal Declaration of Human Rights Article 27&lt;/a&gt; which states that &amp;ldquo;everyone has the right freely to &amp;hellip; share in scientific advancement and its benefits.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Science is ultimately a public endeavor, and making that dream a reality now appears possible with blockchains.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&#34;https://db.erisindustries.com//science/2016/03/15/chains-and-science-how-to/&#34; target=&#34;_blank&#34;&gt;Part 2&lt;/a&gt; for slightly more practical solutions.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>